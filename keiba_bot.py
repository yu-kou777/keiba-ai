import requests
from bs4 import BeautifulSoup
import pandas as pd
import sys
import re
import time
import json

# --- è¨­å®šï¼šDiscord Webhook URL ---
DISCORD_URL = "https://discordapp.com/api/webhooks/1473026116825645210/9eR_UIp-YtDqgKem9q4cD9L2wXrqWZspPaDhTLB6HjRQyLZU-gaUCKvKbf2grX7msal3"

LAB_PLACE_MAP = {"æœ­å¹Œ":"01","å‡½é¤¨":"02","ç¦å³¶":"03","æ–°æ½Ÿ":"04","æ±äº¬":"05","ä¸­å±±":"06","ä¸­äº¬":"07","äº¬éƒ½":"08","é˜ªç¥":"09","å°å€‰":"10"}

def safe_float(value):
    """å®‰å…¨ã«æ•°å€¤ã‚’å¤‰æ›ã™ã‚‹ç‰©ç†ãƒ•ã‚£ãƒ«ã‚¿"""
    try:
        # (0.2)ã®ã‚ˆã†ãªæ‹¬å¼§ä»˜ãã‚„ã€å…¨è§’æ•°å­—ã«ã‚‚å¯¾å¿œ
        clean = re.sub(r'[^\d\.-]', '', str(value))
        return float(clean)
    except:
        return 99.9 # è¨ˆæ¸¬ä¸èƒ½ãªå ´åˆã¯ã€Œç„¡é™é ã€ã¨ã—ã¦æ‰±ã†

def analyze_singularity(horse_url, current_odds):
    """ã€æ•™æˆã®å¿ƒè‡“éƒ¨ã€‘éå»3èµ°ã®æ™‚ç©ºé–“è§£æ"""
    headers = {"User-Agent": "Mozilla/5.0"}
    try:
        # ã‚µãƒ¼ãƒãƒ¼ã¸ã®ç¤¼å„€ï¼ˆå¾…æ©Ÿï¼‰
        time.sleep(0.5)
        
        # URLã®å®Œå…¨æ€§ãƒã‚§ãƒƒã‚¯
        if not horse_url.startswith("http"):
            horse_url = "https://www.keibalab.jp" + horse_url
            
        res = requests.get(horse_url, headers=headers, timeout=10)
        soup = BeautifulSoup(res.text, 'html.parser')
        
        # éå»èµ°ãƒ†ãƒ¼ãƒ–ãƒ«å–å¾—ï¼ˆå¤±æ•—æ™‚ã¯å³æ’¤é€€ï¼‰
        rows = soup.select('table.db-horse-table tbody tr')
        if not rows: return 0, False, "ãƒ‡ãƒ¼ã‚¿ãªã—"
        
        diffs = []
        
        # ç›´è¿‘3èµ°ã‚’ã‚¹ã‚­ãƒ£ãƒ³
        for row in rows[:3]:
            tds = row.find_all('td')
            # åˆ—ä¸è¶³ã‚„ãƒ‡ãƒ¼ã‚¿æ¬ æã‚’ã‚¹ã‚­ãƒƒãƒ—
            if len(tds) < 10: continue
            
            # ã‚¿ã‚¤ãƒ å·®ã‚’æ¢ã™ï¼ˆåˆ—å›ºå®šã§ã¯ãªãã€å†…å®¹ã‹ã‚‰æ¢ç´¢ï¼‰
            found_diff = False
            for td in tds:
                txt = td.text.strip()
                # "0.1" ã‚„ "(0.5)" ã®ã‚ˆã†ãªãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æ¢ã™
                if re.match(r'^\(?\-?\d+\.\d+\)?$', txt):
                    val = safe_float(txt)
                    if val < 5.0: # 5ç§’ä»¥ä¸Šã®å·®ã¯ç•°å¸¸å€¤ã¨ã—ã¦é™¤å¤–
                        diffs.append(val)
                        found_diff = True
                        break
            
            # è¦‹ã¤ã‹ã‚‰ãªã‹ã£ãŸå ´åˆã€ç€é †ã‹ã‚‰æ¨æ¸¬ï¼ˆ1ç€ãªã‚‰0.0ã¨ã™ã‚‹ï¼‰
            if not found_diff:
                if "1" in tds[11].text.strip(): # 12åˆ—ç›®ã‚ãŸã‚ŠãŒç€é †
                    diffs.append(0.0)

        if not diffs: return 0, False, "ã‚¿ã‚¤ãƒ å·®ä¸æ˜"
        
        # --- ç‰©ç†å­¦çš„ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚° ---
        # 1. åæŸæ€§: 0.3ç§’ä»¥å†…ã®ã€Œè‚‰è–„ã€å›æ•°
        score = sum(60 for d in diffs if d <= 0.3)
        
        # 2. å®‰å®šæ€§: å¹³å‡ã‚¿ã‚¤ãƒ å·®
        avg_diff = sum(diffs) / len(diffs)
        score += max(0, 1.5 - avg_diff) * 20
        
        # 3. ã‚«ã‚ªã‚¹æ¤œçŸ¥ (ç©´é¦¬ãƒ•ãƒ©ã‚°): èƒ½åŠ›ãŒé«˜ã„(å·®ãŒå°ã•ã„)ã®ã«äººæ°—ãŒãªã„
        # ã‚¢ãƒ«ãƒ‡ãƒãƒ©ãƒ³Sã®15ç•ªã‚’æ‰ãˆã‚‹ãŸã‚ã®ãƒ­ã‚¸ãƒƒã‚¯
        is_chaos = (avg_diff <= 0.8 and current_odds > 15.0)
        
        return score, is_chaos, f"å¹³å‡å·®:{avg_diff:.2f}"
        
    except Exception as e:
        print(f"  âš ï¸ åˆ†æã‚¹ã‚­ãƒƒãƒ—({horse_url}): {e}")
        return 0, False, "ã‚¨ãƒ©ãƒ¼"

def get_race_data(date_str, place_name, race_num):
    # å®‰å…¨è£…ç½®: æ—¥ä»˜æœªå…¥åŠ›ãªã‚‰ã‚¢ãƒ«ãƒ‡ãƒãƒ©ãƒ³Sã‚’ã‚»ãƒƒãƒˆ
    if not date_str or len(date_str) < 8:
        print("âš ï¸ æ—¥ä»˜è‡ªå‹•è¨­å®š: 20260207 (ã‚¢ãƒ«ãƒ‡ãƒãƒ©ãƒ³S)")
        date_str = "20260207"
        place_name = "äº¬éƒ½"
        race_num = "11"

    p_code = LAB_PLACE_MAP.get(place_name, "08") # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆäº¬éƒ½
    r_num = str(race_num).zfill(2)
    url = f"https://www.keibalab.jp/db/race/{date_str}{p_code}{r_num}/"
    
    print(f"ğŸ“¡ è¦³æ¸¬é–‹å§‹: {url}")
    headers = {"User-Agent": "Mozilla/5.0"}
    
    try:
        res = requests.get(url, headers=headers, timeout=15)
        res.encoding = 'utf-8'
        soup = BeautifulSoup(res.text, 'html.parser')
        
        t_elem = soup.select_one('h1.raceTitle')
        title = t_elem.text.strip().replace('\n', ' ') if t_elem else "ãƒ¬ãƒ¼ã‚¹åä¸æ˜"
        print(f"ğŸ å¯¾è±¡ãƒ¬ãƒ¼ã‚¹: {title}")
        
        horses = []
        rows = soup.find_all('tr')
        
        for row in rows:
            try:
                # é¦¬åãƒªãƒ³ã‚¯å¿…é ˆ
                name_tag = row.select_one('a[href*="/db/horse/"]')
                if not name_tag: continue
                
                # é¦¬å
                name = name_tag.text.strip()
                
                # é¦¬ç•ªï¼ˆçµ¶å¯¾åº§æ¨™ã§ã¯ãªãç›¸å¯¾æ¢ç´¢ï¼‰
                umaban = "0"
                tds = row.find_all('td')
                for i, td in enumerate(tds):
                    if td == name_tag.find_parent('td'):
                        # é¦¬åã®å·¦éš£ã®ã‚»ãƒ«ã‚’è¦‹ã‚‹
                        if i > 0:
                            prev_txt = tds[i-1].text.strip()
                            if prev_txt.isdigit(): umaban = prev_txt
                        break
                
                if umaban == "0": continue # é¦¬ç•ªå–ã‚Œãªã‘ã‚Œã°ã‚¹ã‚­ãƒƒãƒ—

                # ã‚ªãƒƒã‚º (æ•°å€¤æŠ½å‡º)
                odds = 99.9
                odds_match = re.search(r'(\d{1,4}\.\d{1})', row.text)
                if odds_match: odds = float(odds_match.group(1))
                
                # é¨æ‰‹
                jockey = row.select_one('a[href*="/db/jockey/"]').text.strip() if row.select_one('a[href*="/db/jockey/"]') else ""

                # --- è©³ç´°è§£æå®Ÿè¡Œ ---
                score, is_chaos, note = analyze_singularity(name_tag.get('href'), odds)
                
                # é¨æ‰‹è£œæ­£ (ãƒ«ãƒ¡ãƒ¼ãƒ«ã€å·ç”°ã€æ­¦è±Šã€å‚äº•ã€æˆ¸å´)
                if any(x in jockey for x in ['ãƒ«ãƒ¡', 'å·ç”°', 'æ­¦è±Š', 'å‚äº•', 'æˆ¸å´']):
                    score += 10
                
                print(f"  âˆš {umaban}ç•ª {name}: Score {score:.1f} ({note})")
                
                horses.append({
                    "num": int(umaban),
                    "name": name,
                    "score": score,
                    "is_ana": is_chaos,
                    "odds": odds
                })
                
            except Exception as e:
                print(f"  âš ï¸ è¡Œè§£æã‚¨ãƒ©ãƒ¼: {e}")
                continue
                
        return horses, title
        
    except Exception as e:
        print(f"âŒ è‡´å‘½çš„é€šä¿¡ã‚¨ãƒ©ãƒ¼: {e}")
        return [], "ã‚¨ãƒ©ãƒ¼"

def send_to_discord(horses, title, d, p, r):
    if not horses:
        print("âŒ é€ä¿¡ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
        return

    # ã‚¹ã‚³ã‚¢é †ã«ã‚½ãƒ¼ãƒˆ
    df = pd.DataFrame(horses).sort_values('score', ascending=False).reset_index(drop=True)
    
    # --- æ•™æˆã®24ç‚¹ãƒ•ã‚©ãƒ¼ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³ ---
    # è»¸: 1ä½ã€2ä½
    axis = df.head(2)['num'].tolist()
    
    # 2åˆ—ç›®: ä¸Šä½4é ­
    row2 = df.head(4)['num'].tolist()
    
    # 3åˆ—ç›®: ä¸Šä½4é ­ + ç©´ãƒ•ãƒ©ã‚°æŒã¡ + è£œæ¬ 
    ana_list = df[df['is_ana']]['num'].tolist()
    # ç©´é¦¬ã‚’å„ªå…ˆçš„ã«ã­ã˜è¾¼ã‚€
    candidates = row2 + ana_list + df.iloc[4:8]['num'].tolist()
    # é‡è¤‡å‰Šé™¤ã—ã¦å…ˆé ­6é ­
    row3 = list(dict.fromkeys(candidates))[:6]

    # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸æ§‹ç¯‰
    buy_str = (
        f"**1ç€**: {', '.join(map(str, axis))}\n"
        f"**2ç€**: {', '.join(map(str, row2))}\n"
        f"**3ç€**: {', '.join(map(str, row3))}"
    )
    
    payload = {
        "username": "æ•™æˆAI (ä¸æ²ˆè‰¦ãƒ¢ãƒ¼ãƒ‰) ğŸ‡",
        "embeds": [{
            "title": f"ğŸ¯ {p}{r}R {title}",
            "description": f"ğŸ“… {d} | **ã‚¨ãƒãƒ«ã‚®ãƒ¼åŠ¹ç‡æœ€å¤§åŒ– (24ç‚¹)**",
            "color": 15105570, # Orange
            "fields": [
                {"name": "ğŸ‘‘ 1ç€è»¸ (ç‰¹ç•°ç‚¹)", "value": f"**{', '.join(map(str, axis))}**", "inline": True},
                {"name": "ğŸ 2ç€å€™è£œ (4é ­)", "value": f"{', '.join(map(str, row2))}", "inline": True},
                {"name": "ğŸŒ€ 3ç€å€™è£œ (6é ­)", "value": f"{', '.join(map(str, row3))}", "inline": False},
                {"name": "ğŸ’° è²·ã„ç›®ãƒ•ã‚©ãƒ¼ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³", "value": buy_str, "inline": False},
                {"name": "ğŸ“Š è§£æã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹", "value": "å…¨é ­ã‚¹ã‚­ãƒ£ãƒ³å®Œäº†ã€‚ã‚¿ã‚¤ãƒ å·®æ¬ æç­‰ã®ãƒã‚¤ã‚ºé™¤å»æ¸ˆã¿ã€‚", "inline": False}
            ]
        }]
    }
    
    try:
        res = requests.post(DISCORD_URL, json=payload)
        print(f"âœ… Discordé€ä¿¡å®Œäº†: Status {res.status_code}")
    except Exception as e:
        print(f"âŒ é€ä¿¡ã‚¨ãƒ©ãƒ¼: {e}")

if __name__ == "__main__":
    # å¼•æ•°ã‚¨ãƒ©ãƒ¼å¯¾ç­–
    try:
        args = sys.argv
        date = args[1] if len(args) > 1 else "20260207"
        place = args[2] if len(args) > 2 else "äº¬éƒ½"
        race = args[3] if len(args) > 3 else "11"
    except:
        date, place, race = "20260207", "äº¬éƒ½", "11"
    
    h_list, t_str = get_race_data(date, place, race)
    send_to_discord(h_list, t_str, date, place, race)
