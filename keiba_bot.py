import requests
from requests.adapters import HTTPAdapter
from urllib3.util.retry import Retry
import urllib3
from bs4 import BeautifulSoup
import pandas as pd
import sys
import re
import time
import random
import statistics

# SSLè­¦å‘Šç„¡è¦–
urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

# --- Discordæ¥ç¶šè¨­å®š ---
DISCORD_URL = "https://discordapp.com/api/webhooks/1473026116825645210/9eR_UIp-YtDqgKem9q4cD9L2wXrqWZspPaDhTLB6HjRQyLZU-gaUCKvKbf2grX7msal3"

LAB_PLACE_MAP = {"æœ­å¹Œ":"01","å‡½é¤¨":"02","ç¦å³¶":"03","æ–°æ½Ÿ":"04","æ±äº¬":"05","ä¸­å±±":"06","ä¸­äº¬":"07","äº¬éƒ½":"08","é˜ªç¥":"09","å°å€‰":"10"}

def get_stealth_headers():
    user_agents = [
        "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122.0.0.0 Safari/537.36",
        "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/17.3 Safari/605.1.15"
    ]
    return {
        "User-Agent": random.choice(user_agents),
        "Accept": "text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,*/*;q=0.8",
        "Accept-Language": "ja,en-US;q=0.9,en;q=0.8",
        "Referer": "https://www.google.com/",
        "Connection": "keep-alive",
        "Upgrade-Insecure-Requests": "1"
    }

def create_session():
    session = requests.Session()
    retries = Retry(total=3, backoff_factor=1, status_forcelist=[500, 502, 503, 504])
    session.mount("https://", HTTPAdapter(max_retries=retries))
    return session

def safe_float(value):
    try:
        return float(re.sub(r'[^\d\.-]', '', str(value)))
    except: return 99.9

def analyze_potential_energy(session, horse_url, odds):
    """
    ã€å¤§ç©´ãƒ»7ç•ªæ•ç²ãƒ­ã‚¸ãƒƒã‚¯ã€‘
    å‹ã¡æ˜Ÿã‚ˆã‚Šã‚‚ã€Œæƒœæ•—ï¼ˆã‚¿ã‚¤ãƒ å·®0.1-0.5ï¼‰ã€ã‚’éå¤§è©•ä¾¡ã—ã€
    æ½œåœ¨ã‚¨ãƒãƒ«ã‚®ãƒ¼ã®é«˜ã„é¦¬ã‚’ã‚¹ã‚³ã‚¢ä¸Šä½ã«æŠ¼ã—ä¸Šã’ã‚‹ã€‚
    """
    try:
        if not horse_url.startswith("http"): horse_url = "https://www.keibalab.jp" + horse_url
        time.sleep(random.uniform(1.0, 2.0))
        
        res = session.get(horse_url, headers=get_stealth_headers(), timeout=20, verify=False)
        soup = BeautifulSoup(res.text, 'html.parser')
        rows = soup.select('table.db-horse-table tbody tr')
        if not rows: return 0, False, "ãƒ‡ãƒ¼ã‚¿ãªã—"
        
        diffs = []
        for row in rows[:4]: # ç›´è¿‘4èµ°ã‚’è¦‹ã‚‹
            tds = row.find_all('td')
            if len(tds) < 14: continue
            
            # ã‚¿ã‚¤ãƒ å·®å–å¾—
            val = 99.9
            for td in tds:
                txt = td.text.strip()
                if re.match(r'^\(?\-?\d+\.\d+\)?$', txt):
                    val = safe_float(txt)
                    break
            
            # è¦‹ã¤ã‹ã‚‰ãªã‘ã‚Œã°ç€é †ã‹ã‚‰è£œå®Œ
            if val == 99.9 and len(tds) > 11:
                rank_txt = tds[11].text.strip()
                if rank_txt.isdigit():
                    rank = int(rank_txt)
                    if rank == 1: val = -0.1 # å‹ã¡
                    elif rank <= 3: val = 0.2
                    else: val = 1.0

            if val < 5.0: diffs.append(val)

        if not diffs: return 0, False, "ä¸æ˜"
        
        # --- æ•™æˆã®ã€Œæƒœæ•—ä¿‚æ•°ã€è¨ˆç®— ---
        score = 0
        
        # 1. ã€Œè² ã‘ã¦å¼·ã—ã€ãƒœãƒ¼ãƒŠã‚¹ (0.0ç§’ã€œ0.5ç§’å·®è² ã‘ã‚’æœ€å¤§è©•ä¾¡)
        # 7ç•ªã®ã‚ˆã†ãªã€Œå‹ã¦ãªã„ãŒå¼·ã„é¦¬ã€ã‚’æ‹¾ã†ãŸã‚ã®æ ¸å¿ƒ
        regret_count = sum(1 for d in diffs if 0.0 <= d <= 0.5)
        score += regret_count * 40 
        
        # 2. å®‰å®šåº¦ (æ¨™æº–åå·®çš„ãªè€ƒãˆ)
        avg_diff = sum(diffs) / len(diffs)
        if avg_diff < 0.6: score += 30
        
        # 3. çˆ†ç™ºãƒˆãƒªã‚¬ãƒ¼ (å¤§ç©´ãƒ•ãƒ©ã‚°)
        # ã€Œå¹³å‡ã‚¿ã‚¤ãƒ å·®ãŒè‰¯ã„ã€ã‹ã¤ã€Œã‚ªãƒƒã‚ºãŒç”˜ã„(10å€ä»¥ä¸Š)ã€
        # 15ç•ªã®ã‚ˆã†ãªé¦¬ã‚’ã“ã“ã§æ¤œçŸ¥
        is_chaos = (avg_diff < 0.9 and odds > 10.0)
        if is_chaos: score += 20 # ç©´é¦¬è£œæ­£

        return score, is_chaos, f"å¹³å‡å·®:{avg_diff:.2f}"
        
    except Exception: return 0, False, "ã‚¨ãƒ©ãƒ¼"

def get_race_data(date_str, place_name, race_num):
    if not date_str or len(date_str) < 8: date_str, place_name, race_num = "20260207", "äº¬éƒ½", "11"
    p_code = LAB_PLACE_MAP.get(place_name, "08")
    url = f"https://www.keibalab.jp/db/race/{date_str}{p_code}{str(race_num).zfill(2)}/"
    
    print(f"ğŸ“¡ è§£æé–‹å§‹: {url}")
    session = create_session()
    
    try:
        res = session.get(url, headers=get_stealth_headers(), timeout=30, verify=False)
        res.encoding = 'utf-8'
        soup = BeautifulSoup(res.text, 'html.parser')
        title = soup.select_one('h1.raceTitle').text.strip().replace('\n', ' ') if soup.select_one('h1.raceTitle') else "ãƒ¬ãƒ¼ã‚¹"
        
        horses = []
        rows = soup.find_all('tr')
        
        for row in rows:
            name_tag = row.select_one('a[href*="/db/horse/"]')
            if not name_tag: continue
            try:
                name = name_tag.text.strip()
                umaban = "0"
                tds = row.find_all('td')
                for i, td in enumerate(tds):
                    if td == name_tag.find_parent('td'):
                        if i > 0 and tds[i-1].text.strip().isdigit():
                            umaban = tds[i-1].text.strip()
                        break
                if umaban == "0": continue

                odds = 99.9
                m = re.search(r'(\d{1,4}\.\d{1})', row.text)
                if m: odds = float(m.group(1))
                
                jockey = row.select_one('a[href*="/db/jockey/"]').text.strip() if row.select_one('a[href*="/db/jockey/"]') else ""

                score, is_chaos, note = analyze_potential_energy(session, name_tag.get('href'), odds)
                
                # é¨æ‰‹è£œæ­£ (å°‘ã—æ§ãˆã‚ã«)
                if any(x in jockey for x in ['ãƒ«ãƒ¡', 'å·ç”°', 'æ­¦è±Š', 'å‚äº•']): score += 5
                
                print(f"  âˆš {umaban}ç•ª {name}: {score} ({note})")
                horses.append({"num": int(umaban), "name": name, "score": score, "is_ana": is_chaos})
            except: continue
                
        return horses, title
    except Exception as e:
        print(f"âŒ ã‚¨ãƒ©ãƒ¼: {e}"); return [], "ã‚¨ãƒ©ãƒ¼"

def send_to_discord(horses, title, d, p, r):
    if not horses: return
    df = pd.DataFrame(horses).sort_values('score', ascending=False).reset_index(drop=True)
    
    # --- æ•™æˆã®ã€Œ3é ­ã‚¯ã‚¨ãƒ¼ã‚µãƒ¼ã€æˆ¦ç•¥ ---
    # 1åˆ—ç›®: ã‚¹ã‚³ã‚¢ä¸Šä½3é ­ï¼ˆã“ã“ã«7ç•ªã‚’å…¥ã‚Œã‚‹ï¼ï¼‰
    head_3 = df.head(3)['num'].tolist()
    
    # 2åˆ—ç›®: ä¸Šä½3é ­ + ç©´ãƒ•ãƒ©ã‚°æŒã¡1é ­
    ana_list = df[df['is_ana']]['num'].tolist()
    row2 = list(dict.fromkeys(head_3 + ana_list[:1])) # é‡è¤‡é™¤ã„ã¦æœ€å¤§4é ­
    
    # 3åˆ—ç›®: ä¸Šä½ + ç©´ + è£œæ¬ 
    row3 = list(dict.fromkeys(head_3 + ana_list + df.iloc[3:7]['num'].tolist()))[:7]

    buy_str = (
        f"**1ç€**: {', '.join(map(str, head_3))}\n"
        f"**2ç€**: {', '.join(map(str, row2))}\n"
        f"**3ç€**: {', '.join(map(str, row3))}"
    )
    
    payload = {
        "username": "æ•™æˆAI (3é ­æˆ¦ç•¥ãƒ¢ãƒ¼ãƒ‰) ğŸ‡",
        "embeds": [{
            "title": f"ğŸ¯ {p}{r}R {title}",
            "description": f"ğŸ“… {d} | **å¤§ç©´æ•ç²ãƒ»3é ­é ­ãƒ•ã‚©ãƒ¼ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³**",
            "color": 16711680, # Red
            "fields": [
                {"name": "ğŸ‘‘ 1ç€å€™è£œ (3é ­)", "value": f"**{', '.join(map(str, head_3))}**\n(7ç•ªã®ã‚ˆã†ãªæƒœæ•—çµ„ã‚’æ ¼ä¸Šã’)", "inline": False},
                {"name": "ğŸ 2ç€ãƒ»3ç€ã‚¾ãƒ¼ãƒ³", "value": f"**2ç€**: {', '.join(map(str, row2))}\n**3ç€**: {', '.join(map(str, row3))}", "inline": False},
                {"name": "ğŸ’° æ¨å¥¨è²·ã„ç›®", "value": buy_str, "inline": False},
                {"name": "ğŸ“ˆ æ•™æˆã®ç‹™ã„", "value": "ã€å‹ã£ã¦ã¯ã„ãªã„ãŒã‚¿ã‚¤ãƒ å·®ãŒå„ªç§€ã€ãªé¦¬ã‚’1åˆ—ç›®ã«å›ºå®šã€‚15ç•ªãªã©ã®ã‚«ã‚ªã‚¹ï¼ˆç©´é¦¬ï¼‰ã‚’2ãƒ»3åˆ—ç›®ã§ç¶²ç¾…ã—ã€10ä¸‡ã€œ100ä¸‡ã‚¯ãƒ©ã‚¹ã®é…å½“ã‚’ç‹™ã„æ’ƒã¡ã¾ã™ã€‚", "inline": False}
            ]
        }]
    }
    requests.post(DISCORD_URL, json=payload)
    print("âœ… Discordé€ä¿¡å®Œäº†")

if __name__ == "__main__":
    try:
        args = sys.argv
        date = args[1] if len(args) > 1 else "20260207"
        place = args[2] if len(args) > 2 else "äº¬éƒ½"
        race = args[3] if len(args) > 3 else "11"
    except: date, place, race = "20260207", "äº¬éƒ½", "11"
    
    h, t = get_race_data(date, place, race)
    send_to_discord(h, t, date, place, race)
