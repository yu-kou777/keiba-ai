import requests
from bs4 import BeautifulSoup
import pandas as pd
import sys
import re
import time

# --- è¨­å®šï¼šDiscord Webhook URL ---
DISCORD_URL = "https://discordapp.com/api/webhooks/1473026116825645210/9eR_UIp-YtDqgKem9q4cD9L2wXrqWZspPaDhTLB6HjRQyLZU-gaUCKvKbf2grX7msal3"

LAB_PLACE_MAP = {"æœ­å¹Œ":"01","å‡½é¤¨":"02","ç¦å³¶":"03","æ–°æ½Ÿ":"04","æ±äº¬":"05","ä¸­å±±":"06","ä¸­äº¬":"07","äº¬éƒ½":"08","é˜ªç¥":"09","å°å€‰":"10"}

def analyze_singularity(horse_url, odds):
    """éå»3èµ°ã®ã‚¿ã‚¤ãƒ å·®ã‹ã‚‰ã‚¨ãƒãƒ«ã‚®ãƒ¼å€¤ã‚’ç®—å‡ºï¼ˆã‚¨ãƒ©ãƒ¼å›é¿ç‰ˆï¼‰"""
    headers = {"User-Agent": "Mozilla/5.0"}
    try:
        # ã‚µãƒ¼ãƒãƒ¼è² è·è»½æ¸›ã®ãŸã‚å¾…æ©Ÿ
        time.sleep(0.5)
        res = requests.get("https://www.keibalab.jp" + horse_url, headers=headers, timeout=10)
        res.encoding = 'utf-8'
        soup = BeautifulSoup(res.text, 'html.parser')
        
        # éå»èµ°ãƒ†ãƒ¼ãƒ–ãƒ«ã®å–å¾—ï¼ˆå­˜åœ¨ç¢ºèªï¼‰
        rows = soup.select('table.db-horse-table tbody tr')
        if not rows: return 0, False
        
        diffs = []
        for row in rows[:3]:
            tds = row.find_all('td')
            # åˆ—æ•°ãŒè¶³ã‚Šãªã„å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—
            if len(tds) < 14: continue
            
            # ã‚¿ã‚¤ãƒ å·®ã®æŠ½å‡ºï¼ˆæ­£è¦è¡¨ç¾ã§æ•°å€¤ã®ã¿æŠœãï¼‰
            txt = tds[13].text.strip()
            m = re.search(r'(-?\d+\.\d+)', txt)
            if m: diffs.append(float(m.group(1)))
        
        if not diffs: return 0, False
        
        # --- æ•™æˆã®ç‰¹ç•°ç‚¹ãƒ­ã‚¸ãƒƒã‚¯ ---
        # 1. ã‚¿ã‚¤ãƒ å·®0.3ç§’ä»¥å†…ã®ã€Œå‡ç¸®ã€ã‚’é«˜è©•ä¾¡
        score = sum(50 for d in diffs if d <= 0.3)
        # 2. 0.6ç§’ä»¥å†…ãªã‚‰åŠ ç‚¹ï¼ˆå®‰å®šæ€§ï¼‰
        score += sum(20 for d in diffs if 0.3 < d <= 0.6)
        
        # 3. ç©´é¦¬ãƒ•ãƒ©ã‚°ï¼šèƒ½åŠ›ãŒã‚ã‚‹ã®ã«ã‚ªãƒƒã‚ºãŒé«˜ã„ï¼ˆå¸‚å ´ã®æ­ªã¿ï¼‰
        is_ana = (min(diffs) <= 0.5 and odds > 15.0)
        
        return score, is_ana
    except Exception as e:
        print(f"  âš ï¸ è©³ç´°åˆ†æã‚¹ã‚­ãƒƒãƒ—: {e}")
        return 0, False

def get_race_data(date_str, place_name, race_num):
    # æ—¥ä»˜ã‚¨ãƒ©ãƒ¼é˜²æ­¢
    if not date_str or len(date_str) < 8: date_str = "20260207"
    
    p_code = LAB_PLACE_MAP.get(place_name, "05")
    r_num = str(race_num).zfill(2)
    url = f"https://www.keibalab.jp/db/race/{date_str}{p_code}{r_num}/"
    
    print(f"ğŸ“¡ è¦³æ¸¬é–‹å§‹: {url}")
    headers = {"User-Agent": "Mozilla/5.0"}
    
    try:
        res = requests.get(url, headers=headers, timeout=15)
        if res.status_code != 200:
            print(f"âŒ æ¥ç¶šå¤±æ•—: Status {res.status_code}")
            return [], "æ¥ç¶šã‚¨ãƒ©ãƒ¼"
            
        res.encoding = 'utf-8'
        soup = BeautifulSoup(res.text, 'html.parser')
        
        t_elem = soup.select_one('h1.raceTitle')
        title = t_elem.text.strip().replace('\n', ' ') if t_elem else "ãƒ¬ãƒ¼ã‚¹è§£æ"
        
        horses = []
        rows = soup.find_all('tr')
        
        print(f"ğŸ” ãƒ‡ãƒ¼ã‚¿æŠ½å‡ºä¸­...")
        for row in rows:
            try:
                # é¦¬åãƒªãƒ³ã‚¯ãŒã‚ã‚‹è¡Œã®ã¿å¯¾è±¡
                name_tag = row.select_one('a[href*="/db/horse/"]')
                if not name_tag: continue
                
                tds = row.find_all('td')
                if len(tds) < 5: continue
                
                name = name_tag.text.strip()
                horse_url = name_tag.get('href')
                
                # --- é¦¬ç•ªã®å …ç‰¢ãªå–å¾— ---
                # é¦¬åã‚»ãƒ«ã®ã€Œå·¦éš£ã€ã«ã‚ã‚‹æ•°å­—ã‚’æ¢ã™ï¼ˆã“ã‚ŒãŒæœ€ã‚‚ç¢ºå®Ÿï¼‰
                umaban = "0"
                for i, td in enumerate(tds):
                    if td == name_tag.find_parent('td'):
                        if i > 0:
                            prev_text = tds[i-1].text.strip()
                            if prev_text.isdigit(): umaban = prev_text
                        break
                
                # ã‚ªãƒƒã‚ºå–å¾—ï¼ˆæ•°å€¤ãŒå«ã¾ã‚Œã‚‹ã‚»ãƒ«ã‚’æ¤œç´¢ï¼‰
                odds = 999.0
                match_odds = re.search(r'(\d{1,4}\.\d{1})', row.text)
                if match_odds: odds = float(match_odds.group(1))
                
                # é¨æ‰‹å
                jockey = row.select_one('a[href*="/db/jockey/"]').text.strip() if row.select_one('a[href*="/db/jockey/"]') else "ä¸æ˜"

                # è©³ç´°åˆ†æã¸
                score, is_ana = analyze_singularity(horse_url, odds)
                
                # é¨æ‰‹ãƒœãƒ¼ãƒŠã‚¹ï¼ˆãƒ«ãƒ¡ãƒ¼ãƒ«ã€å·ç”°ã€æ­¦è±Šã€å‚äº•ã€æˆ¸å´ï¼‰
                if any(x in jockey for x in ['ãƒ«ãƒ¡', 'å·ç”°', 'æ­¦è±Š', 'å‚äº•', 'æˆ¸å´']):
                    score += 15
                
                horses.append({
                    "num": int(umaban),
                    "name": name,
                    "score": score,
                    "is_ana": is_ana,
                    "odds": odds
                })
                print(f"  âˆš {umaban}ç•ª {name}: è§£æå®Œäº† (Score: {score})")
                
            except Exception as e:
                # 1é ­ã®ã‚¨ãƒ©ãƒ¼ã§å…¨ä½“ã‚’æ­¢ã‚ãªã„
                continue
                
        return horses, title
    except Exception as e:
        print(f"âŒ é‡å¤§ã‚¨ãƒ©ãƒ¼: {e}")
        return [], "ã‚¨ãƒ©ãƒ¼"

def send_to_discord(horses, title, d, p, r):
    if not horses:
        print("âš ï¸ é€ä¿¡ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
        return

    # ã‚¹ã‚³ã‚¢é †ã«ã‚½ãƒ¼ãƒˆ
    df = pd.DataFrame(horses).sort_values('score', ascending=False).reset_index(drop=True)
    
    # è»¸ï¼ˆãƒˆãƒƒãƒ—2ï¼‰
    axis = df.head(2)
    axis_nums = axis['num'].tolist()
    
    # 2åˆ—ç›®ï¼ˆãƒˆãƒƒãƒ—3ï¼‹ç©´é¦¬ï¼‰
    row2_candidates = df.head(3)['num'].tolist()
    
    # 3åˆ—ç›®ï¼ˆãƒˆãƒƒãƒ—5ï¼‹ç©´ãƒ•ãƒ©ã‚°æŒã¡ï¼‰
    ana_list = df[df['is_ana']]['num'].tolist()
    row3_candidates = list(set(df.head(5)['num'].tolist() + ana_list))[:6] # æœ€å¤§6é ­
    
    # ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆä½œæˆ
    msg_title = f"ğŸ¯ {p}{r}R {title}"
    axis_str = ", ".join(map(str, axis_nums))
    row2_str = ", ".join(map(str, row2_candidates))
    row3_str = ", ".join(map(str, row3_candidates))
    
    # æ¨å¥¨è²·ã„ç›®ï¼ˆ1ç€-2ç€-3ç€ï¼‰
    kai_me = f"1ç€: {axis_str}\n2ç€: {row2_str}\n3ç€: {row3_str}"
    
    payload = {
        "username": "æ•™æˆAI (ç‰©ç†çš„3é€£å˜) ğŸ‡",
        "embeds": [{
            "title": msg_title,
            "description": f"ğŸ“… {d} | **ã‚¨ãƒãƒ«ã‚®ãƒ¼åŠ¹ç‡æœ€å¤§åŒ–ãƒ¢ãƒ‡ãƒ«**",
            "color": 3066993,
            "fields": [
                {"name": "ğŸ‘‘ 1ç€è»¸ (ç‰¹ç•°ç‚¹)", "value": f"**{axis_str}**", "inline": True},
                {"name": "ğŸ 2åˆ—ç›® (ã‚¤ãƒ™ãƒ³ãƒˆåœ°å¹³ç·š)", "value": f"**{row2_str}**", "inline": True},
                {"name": "ğŸŒ€ 3åˆ—ç›® (ã‚«ã‚ªã‚¹é ˜åŸŸ)", "value": f"{row3_str}", "inline": False},
                {"name": "ğŸ’° æ•™æˆã®æ¨å¥¨ãƒ•ã‚©ãƒ¼ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³", "value": kai_me, "inline": False},
                {"name": "ğŸ“ˆ è§£æã‚µãƒãƒªãƒ¼", "value": "è»¸é¦¬ã®2ç€ãƒ»3ç€æ¼ã‚Œã‚’ã‚«ãƒãƒ¼ã—ã¤ã¤ã€ã‚¿ã‚¤ãƒ å·®ã®åæŸï¼ˆ0.3ç§’ä»¥å†…ï¼‰ãŒè¦‹ã‚‰ã‚Œã‚‹é¦¬ã‚’2åˆ—ç›®ã«åšãé…ç½®ã—ã¾ã—ãŸã€‚", "inline": False}
            ]
        }]
    }
    
    try:
        res = requests.post(DISCORD_URL, json=payload)
        print(f"âœ… Discordé€ä¿¡å®Œäº†: {res.status_code}")
    except Exception as e:
        print(f"âŒ Discordé€ä¿¡å¤±æ•—: {e}")

if __name__ == "__main__":
    args = sys.argv
    # å¼•æ•°ãŒãªã„å ´åˆã¯ã‚¢ãƒ«ãƒ‡ãƒãƒ©ãƒ³Sã‚’ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã«
    date = args[1] if len(args) > 1 else "20260207"
    place = args[2] if len(args) > 2 else "äº¬éƒ½"
    race = args[3] if len(args) > 3 else "11"
    
    h_list, t_str = get_race_data(date, place, race)
    send_to_discord(h_list, t_str, date, place, race)
