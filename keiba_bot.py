import requests
from bs4 import BeautifulSoup
import pandas as pd
import sys
import re
import time

# --- è¨­å®šï¼šDiscord Webhook URL ---
DISCORD_URL = "https://discordapp.com/api/webhooks/1473026116825645210/9eR_UIp-YtDqgKem9q4cD9L2wXrqWZspPaDhTLB6HjRQyLZU-gaUCKvKbf2grX7msal3"

LAB_PLACE_MAP = {"æœ­å¹Œ":"01","å‡½é¤¨":"02","ç¦å³¶":"03","æ–°æ½Ÿ":"04","æ±äº¬":"05","ä¸­å±±":"06","ä¸­äº¬":"07","äº¬éƒ½":"08","é˜ªç¥":"09","å°å€‰":"10"}

def get_performance_details(horse_url):
    """ãƒ†ã‚¯ãƒ‹ã‚«ãƒ«åˆ†æï¼šéå»3èµ°ã®ã‚¿ã‚¤ãƒ å·®ã‹ã‚‰ã€åæŸã¨çˆ†ç™ºã€ã‚’è©•ä¾¡ã™ã‚‹"""
    headers = {"User-Agent": "Mozilla/5.0"}
    try:
        time.sleep(0.4)
        res = requests.get("https://www.keibalab.jp" + horse_url, headers=headers, timeout=10)
        res.encoding = 'utf-8'
        soup = BeautifulSoup(res.text, 'html.parser')
        rows = soup.select('table.db-horse-table tbody tr')
        
        diffs = []
        breakout_points = 0 # çªãæŠœã‘æœŸå¾…å€¤
        
        for row in rows[:3]:
            tds = row.find_all('td')
            if len(tds) > 13:
                txt = tds[13].text.strip()
                match = re.search(r'(-?\d+\.\d+)', txt)
                if match:
                    d = float(match.group(1))
                    diffs.append(d)
                    # 7ç•ªã‚’è»¸ã«ã™ã‚‹ãŸã‚ã®æ ¸å¿ƒãƒ­ã‚¸ãƒƒã‚¯ï¼š
                    # 0.3ç§’ä»¥å†…ã®åƒ…å·®ã‚’ã€Œçˆ†ç™ºå¯¸å‰ã€ã¨ã—ã¦è¶…é«˜è©•ä¾¡
                    if d <= 0.3: breakout_points += 40
                    elif d <= 0.6: breakout_points += 15
        
        if not diffs: return 0
        
        # ã‚¿ã‚¤ãƒ å·®ã®å¹³å‡å€¤ã«ã‚ˆã‚‹åŸºç¤ç‚¹ï¼ˆå°ã•ã„ã»ã©è‰¯ã„ï¼‰
        avg_diff = sum(diffs) / len(diffs)
        base_score = max(0, 1.5 - avg_diff) * 20
        
        return base_score + breakout_points
    except: return 0

def get_lab_data(date_str, place_name, race_num):
    p_code = LAB_PLACE_MAP.get(place_name, "05")
    r_num = str(race_num).zfill(2)
    base_url = f"https://www.keibalab.jp/db/race/{date_str}{p_code}{r_num}/"
    headers = {"User-Agent": "Mozilla/5.0"}
    
    try:
        print(f"ğŸš€ ã€7ç•ªè»¸ãƒ»é¸å®šãƒ­ã‚¸ãƒƒã‚¯ã€‘ãƒ†ã‚¯ãƒ‹ã‚«ãƒ«åˆ†æå®Ÿè¡Œä¸­...")
        res = requests.get(base_url, headers=headers, timeout=10)
        res.encoding = 'utf-8'
        soup = BeautifulSoup(res.text, 'html.parser')
        title = soup.select_one('h1.raceTitle').text.strip().replace('\n', ' ') if soup.select_one('h1.raceTitle') else "è§£æ"
        
        horses, seen_num = [], set()
        rows = soup.find_all('tr')
        
        for row in rows:
            name_tag = row.select_one('a[href*="/db/horse/"]')
            if not name_tag or len(row.find_all('td')) < 5: continue
            
            try:
                name = name_tag.text.strip()
                horse_url = name_tag.get('href')
                
                # é¦¬ç•ªç‰¹å®š
                td_list = row.find_all('td')
                umaban = ""
                for td in td_list:
                    if td.text.strip().isdigit() and 1 <= int(td.text.strip()) <= 18:
                        umaban = td.text.strip()
                        if td.find_next_sibling() and td.find_next_sibling().select_one('a[href*="/db/horse/"]'): break
                
                if not umaban or umaban in seen_num: continue
                seen_num.add(umaban)

                jockey = row.select_one('a[href*="/db/jockey/"]').text.strip() if row.select_one('a[href*="/db/jockey/"]') else "ä¸æ˜"
                odds = float(re.search(r'(\d{1,4}\.\d{1})', row.text).group(1)) if re.search(r'(\d{1,4}\.\d{1})', row.text) else 999.0

                # ãƒ†ã‚¯ãƒ‹ã‚«ãƒ«åˆ†æ (ã‚¿ã‚¤ãƒ å·®ãƒ»å®‰å®šæ€§)
                technical_score = get_performance_details(horse_url)
                
                # é¨æ‰‹è£œæ­£ï¼ˆå°‘ã—æŠ‘ãˆã‚ã«ã—ã¦èƒ½åŠ›ã‚’å„ªå…ˆï¼‰
                j_bonus = 10 if any(x in jockey for x in ['ãƒ«ãƒ¡', 'å·ç”°', 'æ­¦è±Š', 'å‚äº•', 'æˆ¸å´', 'å²©ç”°', 'é®«å³¶']) else 0
                
                total_score = technical_score + j_bonus
                
                horses.append({"num": int(umaban), "name": name, "jockey": jockey, "odds": odds, "score": total_score})
                print(f"  ğŸ” {umaban}ç•ª {name}: ã‚¹ã‚³ã‚¢ç®—å‡ºå®Œäº†")
            except: continue
            
        return horses, title
    except Exception as e:
        print(f"âŒ ã‚¨ãƒ©ãƒ¼: {e}"); return [], "ã‚¨ãƒ©ãƒ¼"

def send_discord(horses, title, d, p, r):
    if not horses: return
    df = pd.DataFrame(horses).sort_values('score', ascending=False).reset_index(drop=True)
    
    # è»¸é¦¬ï¼ˆä¸Šä½2é ­ï¼‰
    axis = df.head(2)
    a_nums = axis['num'].tolist()
    
    # ç›¸æ‰‹å€™è£œï¼ˆç´ï¼š3ä½ã€œ4ä½ï¼‰
    opponents = df.iloc[2:4]['num'].tolist()
    
    # 2åˆ—ç›®ãƒ¡ãƒ³ãƒãƒ¼ï¼ˆè»¸ï¼‹ç›¸æ‰‹ï¼‰
    second_row = a_nums + opponents
    
    payload = {
        "username": "ã‚†ãƒ¼ã“ã†AI (ãƒ†ã‚¯ãƒ‹ã‚«ãƒ«åˆ†æ) ğŸ‡",
        "embeds": [{
            "title": f"ğŸ¯ {p}{r}R {title}",
            "description": f"ğŸ“… {d} | **ã€3é€£å˜ 2è»¸ãƒ•ã‚©ãƒ¼ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³ã€‘**",
            "color": 15548997,
            "fields": [
                {"name": "ğŸ‘‘ 1ç€è»¸ (2é ­)", "value": f"**{a_nums[0]}ç•ª** ({axis.iloc[0]['name']})\n**{a_nums[1]}ç•ª** ({axis.iloc[1]['name']})", "inline": False},
                {"name": "ğŸ 2ãƒ»3ç€å€™è£œ", "value": f"{', '.join(map(str, opponents))}", "inline": False},
                {"name": "ğŸ’° æ¨å¥¨è²·ã„ç›®: 3é€£å˜", "value": f"**1ç€**: {a_nums[0]}, {a_nums[1]}\n**2ç€**: {', '.join(map(str, second_row))}\n**3ç€**: {', '.join(map(str, second_row))}", "inline": False},
                {"name": "ğŸ“ˆ ãƒ­ã‚¸ãƒƒã‚¯", "value": "éå»3èµ°ã®åƒ…å·®ï¼ˆ0.3ç§’ä»¥å†…ï¼‰ã‚’æœ€é‡è¦è¦–ã—ã€å‹ã¡ãã‚Œã‚‹èƒ½åŠ›ã‚’æ•°å€¤åŒ–ã—ã¾ã—ãŸã€‚3ç€ã¯å…¨æµã—ã‚’å»ƒæ­¢ã—ã€ä¸Šä½é™£ã§å›ºã‚ã¦ã„ã¾ã™ã€‚", "inline": False}
            ]
        }]
    }
    requests.post(DISCORD_URL, json=payload)

if __name__ == "__main__":
    args = sys.argv
    date = args[1] if len(args) > 1 and args[1] != "" else "20260222"
    place = args[2] if len(args) > 2 and args[2] != "" else "æ±äº¬"
    race = args[3] if len(args) > 3 else "11"
    h, t = get_lab_data(date, place, race)
    send_discord(h, t, date, place, race)
