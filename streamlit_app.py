import streamlit as st
import pandas as pd
import requests
from bs4 import BeautifulSoup
import re
import time
import random

# --- è¨­å®š ---
HEADERS = {
    "User-Agent": "Mozilla/5.0 (iPhone; CPU iPhone OS 15_0 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/15.0 Mobile/15E148 Safari/604.1"
}

@st.cache_data(ttl=86400)
def get_latest_sire_leading():
    """ æœ€æ–°ã®ç¨®ç‰¡é¦¬ãƒ©ãƒ³ã‚­ãƒ³ã‚°TOP50ã‚’å–å¾— """
    url = "https://db.netkeiba.com/?pid=sire_leading"
    try:
        res = requests.get(url, headers=HEADERS, timeout=10)
        soup = BeautifulSoup(res.content, "html.parser")
        rows = soup.find("table", class_="nk_tb_common").find_all("tr")[1:51]
        return [row.find_all("td")[1].text.strip() for row in rows]
    except:
        return ["ã‚­ã‚ºãƒŠ", "ã‚¨ãƒ”ãƒ•ã‚¡ãƒã‚¤ã‚¢", "ãƒ­ãƒ¼ãƒ‰ã‚«ãƒŠãƒ­ã‚¢"]

def get_race_details(race_id_lab):
    """ ç«¶é¦¬ãƒ©ãƒœã‹ã‚‰åŸºæœ¬æƒ…å ±ï¼ˆé¦¬åã€ã‚ªãƒƒã‚ºã€çˆ¶ã€æ¯çˆ¶ï¼‰ã‚’å–å¾— """
    url = f"https://www.keibalab.jp/db/race/{race_id_lab}/"
    try:
        time.sleep(random.uniform(1.5, 3.0)) # è² è·è»½æ¸›
        res = requests.get(url, headers=HEADERS, timeout=10)
        res.encoding = res.apparent_encoding
        soup = BeautifulSoup(res.text, "html.parser")
        
        table = soup.find("table", class_="table_01")
        if not table: return None
        
        data = []
        for row in table.find_all("tr")[1:]:
            cols = row.find_all("td")
            if len(cols) > 12:
                name = cols[3].text.strip()
                # è¡€çµ±æƒ…å ±ã‚’å–å¾—
                sire = cols[4].text.split('\n')[0].strip()
                bms = cols[4].text.split('\n')[1].strip() if '\n' in cols[4].text else ""
                odds = cols[12].text.strip()
                # ã€æ–°æ©Ÿèƒ½ã€‘å‰èµ°ç€å·®ï¼ˆç°¡æ˜“å–å¾—ï¼šãƒ©ãƒœã®å‡ºé¦¬è¡¨ã«ã‚ã‚‹ã€Œå‰èµ°ã€æ¬„ã‹ã‚‰ï¼‰
                # å®Ÿéš›ã«ã¯ã‚ˆã‚Šè©³ç´°ãªãƒ‘ãƒ¼ã‚¹ãŒå¿…è¦ã§ã™ãŒã€ã¾ãšã¯æ§‹é€ ã‚’ä½œã‚Šã¾ã™
                last_margin = 0.5 # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤
                try:
                    margin_text = cols[14].text # å‰èµ°ç€å·®ã®æ–‡å­—ã‚’æ¢ã™
                    match = re.search(r'([+-]?\d\.\d)', margin_text)
                    if match: last_margin = float(match.group(1))
                except: pass
                
                data.append({
                    "é¦¬ç•ª": cols[1].text.strip(),
                    "é¦¬å": name,
                    "çˆ¶": sire,
                    "æ¯çˆ¶": bms,
                    "ã‚ªãƒƒã‚º": odds,
                    "å‰èµ°ç€å·®": last_margin
                })
        return pd.DataFrame(data)
    except: return None

# --- ãƒ¡ã‚¤ãƒ³ç”»é¢ ---
st.set_page_config(page_title="AIç«¶é¦¬äºˆæƒ³", layout="wide")
st.title("ğŸ‡ AIç«¶é¦¬äºˆæƒ³ï¼šéå»5èµ°è§£æãƒ¢ãƒ‡ãƒ«")

with st.sidebar:
    st.header("åˆ†æè¨­å®š")
    top_sires = get_latest_sire_leading()
    st.write(f"æœ€æ–°ç¨®ç‰¡é¦¬TOP50å–å¾—æ¸ˆã¿")

# IDè‡ªå‹•ç”Ÿæˆï¼ˆäº¬éƒ½11Rãªã©ã®æŒ‡å®šï¼‰
col1, col2, col3 = st.columns(3)
with col1: d = st.text_input("æ—¥ä»˜", "20260207")
with col2: p = st.selectbox("å ´æ‰€", ["05:æ±äº¬", "06:ä¸­å±±", "08:äº¬éƒ½", "09:é˜ªç¥"], index=2)
with col3: r = st.text_input("ãƒ¬ãƒ¼ã‚¹", "11")
race_id = f"{d}{p[:2]}{r}"

if st.button("å…¨è‡ªå‹•è§£æã‚¹ã‚¿ãƒ¼ãƒˆ"):
    with st.spinner("ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã—ã€ã‚¨ã‚¯ã‚»ãƒ«ã®ãƒ­ã‚¸ãƒƒã‚¯ã§è¨ˆç®—ä¸­..."):
        df = get_race_details(race_id)
        
        if df is not None:
            df["ã‚ªãƒƒã‚º"] = pd.to_numeric(df["ã‚ªãƒƒã‚º"], errors='coerce')
            
            # --- ãƒ­ã‚¸ãƒƒã‚¯ï¼šã‚¨ã‚¯ã‚»ãƒ«åŸºæº–ã®è‡ªå‹•åˆ¤å®š ---
            def ai_logic(row):
                score = 50 # åŸºæº–
                # 1. è¡€çµ±ãƒœãƒ¼ãƒŠã‚¹
                if row['çˆ¶'] in top_sires: score += 15
                # 2. å‰èµ°ç€å·®ãƒœãƒ¼ãƒŠã‚¹ï¼ˆã‚¨ã‚¯ã‚»ãƒ«ã®ã€Œ0.4ä»¥å†…ã€ã‚’åæ˜ ï¼‰
                if row['å‰èµ°ç€å·®'] <= 0.4: score += 20
                # 3. æœŸå¾…å€¤è£œæ­£ï¼ˆäººæ°—è–„ã®æ¿€èµ°ç‹™ã„ï¼‰
                if row['ã‚ªãƒƒã‚º'] >= 10.0: score += 10
                return score

            df["AIã‚¹ã‚³ã‚¢"] = df.apply(ai_logic, axis=1)
            # æœŸå¾…å€¤è¨ˆç®—
            df["æœŸå¾…å€¤"] = (df["AIã‚¹ã‚³ã‚¢"] / 50) * (10 / df["ã‚ªãƒƒã‚º"])
            
            # çµæœè¡¨ç¤º
            st.subheader("ğŸ“Š è§£æçµæœï¼ˆæœŸå¾…å€¤ãƒ©ãƒ³ã‚­ãƒ³ã‚°ï¼‰")
            res_df = df.sort_values("æœŸå¾…å€¤", ascending=False)
            
            # ã‚¹ãƒãƒ›ã§è¦‹ã‚„ã™ãè‰²ä»˜ã‘
            st.dataframe(res_df.style.background_gradient(subset=['æœŸå¾…å€¤'], cmap='YlOrRd'))
            
            # ã‚¹ãƒ†ãƒƒãƒ—3ã¸ã®å¸ƒçŸ³ï¼šè²·ã„ç›®ç”Ÿæˆ
            st.divider()
            st.subheader("ğŸ¯ æ¨å¥¨è²·ã„ç›®")
            top3 = res_df.head(3)['é¦¬ç•ª'].tolist()
            st.success(f"ã€é¦¬é€£BOXã€‘ {' - '.join(top3)}")
        else:
            st.error("ã‚µã‚¤ãƒˆã‹ã‚‰æ‹’å¦ã•ã‚Œã¾ã—ãŸã€‚å°‘ã—æ™‚é–“ã‚’ç½®ã„ã¦ãã ã•ã„ã€‚")
